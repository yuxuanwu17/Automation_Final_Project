{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPnwan4xzPzMdIQiBPJUqY/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"VLI9rEvcF890"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import time\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","import xgboost as xgb\n","from xgboost import XGBClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, matthews_corrcoef\n","from sklearn.metrics import roc_auc_score, average_precision_score\n","from prettytable import PrettyTable\n","from sklearn.neighbors import KNeighborsClassifier\n","import random\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","df = pd.read_csv(\"20000_reduced_featureSelectedAllDataWithY.csv\")\n","print(df.shape)\n","df.head()"]},{"cell_type":"code","source":["dis = df[\"disposition\"]\n","from collections import Counter\n","counter = Counter(dis)\n","print(counter)\n","# estimate scale_pos_weight value\n","estimate = counter[1] / counter[2]\n","# estimate = counter[2] / counter[1]\n","print('The Estimate of scale_pos_weight value for xgboost is: %.3f' % estimate)"],"metadata":{"id":"BX7Om-A4GC2w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# construct the XGBoost model\n","def XGBoostModel(data, initialFile=None, method=\"one-time\",  once_add=1000, query_method = \"random\"):\n","\n","    # split the data into training and testing set with 2:8 ratio\n","    # and evaluate its performance \n","    if method == \"one-time\":\n","        training_data, testing_data = train_test_split(data, test_size=0.2)\n","        y_train = training_data['disposition']\n","        y_test = testing_data['disposition']\n","        X_train = StandardScaler().fit_transform(training_data.drop(\"disposition\",axis = 1))\n","        X_test = StandardScaler().fit_transform(testing_data.drop(\"disposition\",axis = 1))\n","        # jump through grid search\n","        clf = XGBClassifier(n_estimators=10, max_depth=8,\n","                    learning_rate=0.3, n_jobs=-1,random_state=1,scale_pos_weight=estimate,\n","                    use_label_encoder=True).fit(X_train, y_train)\n","        y_pred = clf.predict(X_test)\n","        \n","        # evaluate the model performance\n","        accuracy_scores = []\n","        f1_scores = []\n","        recall_scores = []\n","        precision_scores = []\n","        MCCs = []\n","        auROCs = []\n","        auPRCs = []\n","\n","        # calculate the metrices\n","        accuracy_scores.append(accuracy_score(y_true=y_test, y_pred=y_pred))\n","        f1_scores.append(f1_score(y_true=y_test, y_pred=y_pred))\n","        recall_scores.append(recall_score(y_true=y_test, y_pred=y_pred))\n","        precision_scores.append(precision_score(y_true=y_test, y_pred=y_pred))\n","        MCCs.append(matthews_corrcoef(y_true=y_test, y_pred=y_pred))\n","        auROCs.append(roc_auc_score(y_true=y_test, y_score=clf.predict_proba(X_test)[:, 1]))\n","        auPRCs.append(average_precision_score(y_true=y_test,  y_score=clf.predict_proba(X_test)[:, 0]))\n","\n","        table = PrettyTable()\n","        column_names = ['Accuracy', 'auROC', 'auPRC', 'recall', 'precision', 'f1', 'MCC']\n","        table.add_column(column_names[0], np.round(accuracy_scores, 4))\n","        table.add_column(column_names[1], np.round(auROCs, 4))\n","        table.add_column(column_names[2], np.round(auPRCs, 4))\n","        table.add_column(column_names[3], np.round(recall_scores, 4))\n","        table.add_column(column_names[4], np.round(precision_scores, 4))\n","        table.add_column(column_names[5], np.round(f1_scores, 4))\n","        table.add_column(column_names[6], np.round(MCCs, 4))\n","        return table\n","    elif method == \"iterative\":\n","        # obtain the initial indices from txt file\n","        \n","        initial_df = pd.read_csv(initialFile, sep=\" \", header=None)\n","        initial_index = [x for x in initial_df.iloc[:,0]]\n","        initial = len(initial_index)\n","        remain_index = [x for x in range(0,len(data)) if x not in initial_index]\n","        current_dat = data.iloc[initial_index]\n","        remain_dat = data.iloc[remain_index]\n","        \n","        # set training and testing data\n","        y_train = current_dat['disposition']\n","        y_test = remain_dat['disposition']\n","        X_train = StandardScaler().fit_transform(current_dat.drop(\"disposition\",axis = 1))\n","        X_test = StandardScaler().fit_transform(remain_dat.drop(\"disposition\",axis = 1))\n","        \n","        # evaluate the model performance\n","        sampleNum = []\n","        accuracy_scores = []\n","        f1_scores = []\n","        recall_scores = []\n","        precision_scores = []\n","        MCCs = []\n","        auROCs = []\n","        auPRCs = []\n","        \n","        # construct model\n","        ## jump through grid search\n","        model = XGBClassifier(n_estimators=10, max_depth=8,\n","                    learning_rate=0.3, n_jobs=-1,random_state=1,scale_pos_weight=estimate,\n","                    use_label_encoder=True)\n","        clf = model.fit(X_train, y_train)\n","        # add once_add new samples each time\n","        # calculate the number of round we need to run in total\n","        numRound = ((len(data) - initial)//once_add) + 1\n","        for i in range(numRound+1):\n","            # only continue training when there is unobserved sample \n","            # if len(remain_index) > 0:\n","            # obtain performance\n","            y_pred = clf.predict(X_test)\n","            sampleNum.append(initial+once_add*i)\n","            accuracy_scores.append(accuracy_score(y_true=y_test, y_pred=y_pred))\n","            f1_scores.append(f1_score(y_true=y_test, y_pred=y_pred))\n","            recall_scores.append(recall_score(y_true=y_test, y_pred=y_pred))\n","            precision_scores.append(precision_score(y_true=y_test, y_pred=y_pred))\n","            MCCs.append(matthews_corrcoef(y_true=y_test, y_pred=y_pred))\n","            auROCs.append(roc_auc_score(y_true=y_test, y_score=clf.predict_proba(X_test)[:, 1]))\n","            auPRCs.append(average_precision_score(y_true=y_test,  y_score=clf.predict_proba(X_test)[:, 0]))\n","            # add certain number of samples each time\n","            if query_method == \"random\":\n","                if once_add < len(remain_index):\n","                    print(len(remain_index))\n","                    new_index = random.sample(remain_index, once_add)\n","                # if the number of remaining sample is less than once_add, end the for loop\n","                else:\n","                    break\n","            #################### active learning ####################\n","#             elif query_method == \"\"\n","            #################### active learning ####################\n","            remain_index = [i for i in remain_index if i not in new_index]\n","            new_dat = data.iloc[new_index]\n","            current_dat = pd.concat([current_dat, new_dat])\n","            remain_dat = data.iloc[remain_index]\n","            \n","            # set training and testing data\n","            y_train = current_dat['disposition']\n","            y_test = remain_dat['disposition']\n","            X_train = StandardScaler().fit_transform(current_dat.drop(\"disposition\",axis = 1))\n","            X_test = StandardScaler().fit_transform(remain_dat.drop(\"disposition\",axis = 1))\n","            \n","            clf = model.fit(X_train, y_train)\n","            # print(i)\n","        # print performance table\n","        table = PrettyTable()\n","        column_names = ['sampleNum', 'Accuracy', 'auROC', 'auPRC', 'recall', 'precision', 'f1', 'MCC']\n","        table.add_column(column_names[0], sampleNum)\n","        table.add_column(column_names[1], np.round(accuracy_scores, 4))\n","        table.add_column(column_names[2], np.round(auROCs, 4))\n","        table.add_column(column_names[3], np.round(auPRCs, 4))\n","        table.add_column(column_names[4], np.round(recall_scores, 4))\n","        table.add_column(column_names[5], np.round(precision_scores, 4))\n","        table.add_column(column_names[6], np.round(f1_scores, 4))\n","        table.add_column(column_names[7], np.round(MCCs, 4))\n","        \n","        filename = \"C://CMU/Courses/Automation/Project/res_XGBoost_\" + str(once_add) + \".csv\" \n","        with open(filename, 'w', newline='') as f_output:\n","            f_output.write(table.get_csv_string())\n","        return table\n","            "],"metadata":{"id":"_WPyx_YFGElA"},"execution_count":null,"outputs":[]}]}